"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[590],{4137:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>f});var r=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,i=function(e,t){if(null==e)return{};var n,r,i={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=r.createContext({}),c=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},u=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=c(n),d=i,f=p["".concat(s,".").concat(d)]||p[d]||m[d]||o;return n?r.createElement(f,a(a({ref:t},u),{},{components:n})):r.createElement(f,a({ref:t},u))}));function f(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,a=new Array(o);a[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:i,a[1]=l;for(var c=2;c<o;c++)a[c]=n[c];return r.createElement.apply(null,a)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},5690:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>a,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var r=n(7462),i=(n(7294),n(4137));const o={title:"Introduction",sidebar_position:1},a="Introduction",l={unversionedId:"Getting Started/introduction",id:"Getting Started/introduction",title:"Introduction",description:"What is RLGym?",source:"@site/docs/Getting Started/introduction.md",sourceDirName:"Getting Started",slug:"/Getting Started/introduction",permalink:"/Getting Started/introduction",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"Introduction",sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Overview",permalink:"/Getting Started/overview"}},s={},c=[{value:"What is RLGym?",id:"what-is-rlgym",level:2},{value:"How it Works",id:"how-it-works",level:2},{value:"Getting Started",id:"getting-started",level:2},{value:"Installation",id:"installation",level:2}],u={toc:c},p="wrapper";function m(e){let{components:t,...n}=e;return(0,i.kt)(p,(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"introduction"},"Introduction"),(0,i.kt)("h2",{id:"what-is-rlgym"},"What is RLGym?"),(0,i.kt)("p",null,"RLGym is a Python API for creating reinforcement learning environments. While it was originally designed for the game ",(0,i.kt)("a",{parentName:"p",href:"https://www.rocketleague.com"},"Rocket League"),", the core API is now game-agnostic. This means you can use RLGym to create any kind of environment you want, from simple grid worlds to complex physics simulations. Get an overview of how RLGym works in our ",(0,i.kt)("a",{parentName:"p",href:"/Getting%20Started/overview"},"overview")," section."),(0,i.kt)("h2",{id:"how-it-works"},"How it Works"),(0,i.kt)("p",null,'RLGym provides a simple API for creating fully customizable environments for reinforcement learning projects. Each environment is built from a few core components, which we refer to as "configuration objects". When provided with a set of configuration objects, RLGym will handle the flow of information throughout the environment, and provide a simple interface for learning agents to interact with the environment.'),(0,i.kt)("h2",{id:"getting-started"},"Getting Started"),(0,i.kt)("p",null,"The most developed use of RLGym is for Rocket League. We provide a complete environment implementation that allows users to train agents with ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/ZealanL/rocketsim"},"RocketSim"),", a headless simulator for Rocket League. Users can customize every aspect of the environment by implementing their own ",(0,i.kt)("a",{parentName:"p",href:"/Getting%20Started/overview/"},"Configuration Objects"),", or use the default implementations provided by RLGym. Head over to our ",(0,i.kt)("a",{parentName:"p",href:"/Getting%20Started/quickstart"},"Quick Start Guide")," if you want to jump right in to training a Rocket League agent, or check out our ",(0,i.kt)("a",{parentName:"p",href:"../../Custom%20Environments/custom-environment"},"Custom Environments")," section for a step-by-step guide to creating your own environment with the RLGym API."),(0,i.kt)("h2",{id:"installation"},"Installation"),(0,i.kt)("p",null,"RLGym is split into several packages to keep things modular and lightweight. The core API package has no dependencies, while additional packages provide specific functionality:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# Just the core API\npip install rlgym\n\n# Everything for Rocket League with RocketSim\npip install rlgym[rl-sim]\n\n# Everything for Rocket League with RocketSim and RLViser (visualization)\npip install rlgym[rl-rlviser]\n\n# All packages\npip install rlgym[all]\n")))}m.isMDXComponent=!0}}]);